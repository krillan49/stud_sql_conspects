--                                    Устройство баз данных в PostgreSQL

-- database cluster - одна и более БД, управляемые из под одной инстанции сервера. Например когда мы устанавливаем PostgreSQL, то получаем кластер со специальными утилитарными БД, например tamplate1, которая используется для того чтобы создавать новые БД, она клонируется и из нее создается новая БД

-- Фаилы данных кластера лежат в директории data(часто называется PGDATA). PGDATA - это переменная окружения, указывающая на папку data, тоесть нужна для обращения к ней

-- Для каждой БД есть своя подпапка PGDATA/base

-- Для каждой таблицы и индекса выделяется отдельный фаил. Фаилы по умолчанию бьются по размеру 1Гб, если превышается, то создается еще 1 фаил, но это можно настроить



--                                       Устройство таблиц в PostgreSQL

-- Таблица(хранящаяся по умолчанию в фаилах по 1ГБ) состоит из массива страниц (каждая страница по умолчанию размером 8Кб)

-- Фаил таблицы называется Heap File (не имеет отношение к структуре данных "куча"), он содержит списки неупорядоченных записей различной длинны, структурирован как набор страниц, каждая из которых имеет множество строк



--                               Страницы и строки таблицы в PostgreSQL. TOAST. CTID

-- Каждая страница содержит: заголовок страницы, строки с их заголовками

-- Cтраницы по умолчанию 8Кб, но это не означает что на странице не может быть больших данных/значений превышающих эти 8кб
-- Хранить значения одной строки на разных страницах запрещено и не поддерживается сервером, потому если в строке какойто страницы есть значение превышающее максимальный размер страницы, то оно обрабатывается при помощи механизма TOAST

-- TOAST - the oversized attribute storage technicue. Каждая таблица имеет ассоциированную с ней TOAST-таблицу, в которой хранятся большие значения, нарезанные кусками по 2Кб, а в столбце исходной таблицы помещается ссылка на место в TOAST-таблице, где хранится само значение

-- Страница содержит ссылки на строки (CTID). CTID состоит из пары значений: номера страницы и индекса, используя эту инфу PostgreSQL может быстро обращаться к данным находящимся в тех или иных местах



--                                          FSM и VM фаилы в PostgreSQL

-- Рядом с фаилом таблицы лежит фаил FSM (free space map). Имеет в своем названии суффикс FSM. Он хранит значения округленные до 1/256й от размера страницы, это 32 Байта при размере страницы 8Кб. Он используется для того чтобы сервер понимал куда можно сохранить данные определенных размеров

-- FSM не обновляется при каждом обновлении или удалении строк, тк при удалении и обновлении строки ее старая версия не исчезает сразу из памяти, чтобы поддерживать механизм конкурентного доступа к одним и тем же данным

-- Рядом с фаилом таблицы лежит фаил VM (visibility map), фаил имеет суффикс _VM. Эти фаилы хранят биты - 1 бит на страницу, который, если выставлен в значение 1 показывает, что страница не содержит "дохлых версий строк". Это служит для того чтобы сервер быстрее считывал данные



--                                  VACUUM. Проблема фрагментации данных в PostgreSQL

-- Если вообще не обслуживать БД, то фрагментация данных будет нарастать

-- VACUUM [FULL] - команда для очистки "дохлых" версий строк, тоесть как раз тех, что сразу не удалились из памяти. Эта команда не возвращает память операционной системе, тоесть не удаляет, а просто помечает отрезки памяти, как те которые можно перезаписывать новыми данными.
-- Необходим переодический запуск VACUUM. Активно обновляемые БД рекомендуется проходить с VACUUM каждую ночь

VACUUM      -- команда для очистки "дохлых" версий строк, обычно ее достаточно. Работает параллельно и не берет эксклюзивную блокировку
VACUUM FULL -- с этой опцией производит полный компактинг таблицы, те проведет сжатие таблицы и полную ее перезапись, это долго по времени и требует столько же памяти как и таблица к которой применили данную команду, потому производится редко. Берет эксклюзивную блокировку на чтение и запись таблицы. Потому используем только если удалили очень много данных

ANALYZE -- Собирает статистику о содержимом таблиц (например распределения данных) и сохраняет результаты в специальном системном каталоге pg_statistic, в результате планировщик запросов после этого может использовать статистику для того чтобы выполнить запрос наиболее эффективно. Если не задать никаких параметров то команда отработает по всем таблицам в текущей БД, нужно указать параметр чтобы пройтись только по конкретной таблице, можно так же задать и отдельные колонки, соотв статистика будет собрана только с них.

VACUUM ANALYZE -- можно запускать совместно

-- Autovacuum - демон\бэкграунд процесс - работает в фоне и делает все автоматически, его работа базируется на собираемой сервером статистики апдэйтов и удалений. Включается эвристически, включает множество настраиваемых параметров. По умолчанию включен и отключать его не рекомендуется. По умолчанию работает для всех таблиц в БД, но можно задать и отдельно конкретную



--                                 Индексы в PostgreSQL. Оптимизация выборки записей

-- Индекс - структура данных иобъект базы данных, который можно создавать и удалять. Он позволяет искать значения без полного перебора строк и сокращать время поиска, тоесть ускоряет выборку данных из таблицы за счет дополнительных операций записи и использования дополнительного пространства на диске

-- Так же индексы называют методами доступа, тк индекс устанавливает соотвествие между ключем, являющимся обычно значением индексированного столбца и строками таблицы, в которых этот ключ встречается
-- TID - номер блока фаила и позиции строки внутри блока, они идентифицируют строку

-- Зная ключ или информацию о нем, можно найти требуемую строку, не просмавтривая всю таблицу полностью

-- Оптимизация выборки небольшого числа записей(относительно общего количества записей содержащихся в таблице) - от того сколько записей фильтрует запрос зависит будет ли использован индекс

-- По столбцам с PRIMARY KEY или UNIQUE индекс создается автоматически, по умолчанию будет создаваться b-tree индекс

-- Индексы не бесплатны и требуют определенных затрат на свое поддержание. При операции над проиндексированными данными, например вставка, удаление или обновление строк таблицы - индексы созданные для этих полей должны быть перестроены, причем в рамках той же транзакции. Обновление же полей таблицы по которым не создавались индексы не приводят к перестроению индексов



--                                         Методы сканирования данных

-- Какие именно методы сканирования включать решает оптимизатор

-- 1. Индексное сканирование (index scan) - очень эффективный метод сканирования. Если есть большой набор проиндексированных данных и мы осуществляем поиск по индексам и потенциально в результирующий набор попададет малое количество строк, то оптимизатор включит индексный поиск. Например когда мы ищем строку по конкретному уникальному целочисленному значению в проиндексированном столбце и на миллион значений вернется всего одна строка

-- 2. Исключительно индексное сканирование (index only scan) - самый эффективный метод сканирования. Некоторые индексы хранят вместе с идентификаторами строк сами проиндексированные значения и это позволяет просто прочитать индекс, вообще без обращения к таблицам, забирая результат прямо из индекса. Необходимо лишь заглянуть в карту видимости(VM), чтобы выяснить актуальность индексных записей, тоесть битик выставлен на 1, значит данные актуальны и можно выполнить искл индесное сканирование. В том числе и для этого нужно переодически использовать VACUUM, тк иначе вместо исключительного будет выполнено менее эффективное обычное индексное сканирование

-- 3. Сканирование по битовой карте (bitmap index scan). Подходит если выбрано не так мало как при индексном сканировании, но и не так много как при последовательном. Работает и при поиске более чем по 1 индексу. При увеличении выборки растет вероятность множественного прочтения одних и тех же страниц (теесть еще не прочитанных строк, но находящихся на тех страницах, что уже читались ранее), тогда планировщик может выбрать этот способ сканирования. Сначала возвращает все TID соответсвующие условию и по ним строится битовая карта версий строк, а затем версии строк читаются из таблицы, при этом каждая страница будет прочитана только 1 раз, что уменьшит число прыжков между страницами, а при достаточно больших выборках большое число прыжков может нанести сильный ущерб производительности запроса

-- 4. Последовательное сканирование (sequential scan). Планировщик переключантся на этот тип сканирования при слабой селективности запроса, тоесть запрос должен вернуть значительную долю строк относительно общего числа строк. Даже если поиск идет по проиндексированному столбцу, то при слабой селективности запроса планировщик может наплевать на индексы и пойдет по этому пути сканирования.

-- Иногда плонировщик понимает что проще отсеять строки не подходящие для возрата и просто вернуть все оставшиеся



--                                          Виды индексов в PostgreSQL

SELECT amname FROM pg_am; -- выведет типы индексов доступные на нашем сервере

-- Распространенные индексы:
-- B-tree (сбалансированное дерево)
-- hash   (Хэш-индекс)

-- Специализированные индесы:
-- GiST    (обобщенное дерево поиска)
-- GIN     (обобщенный обратный)
-- SP-GiST (GiST с двоичным разбиением пространства)
-- BRIN    (блочно диапазонный)

-- Все типы индексов имеют собственные ограничения, в том числе и по поддерживаемым операциям, используемым в запросе. Например если в запросе есть оператор > а он не поддерживается заданным типом индекса, то сканирование не будет индексным, а станет обычным последовательным



--                                                  B-tree

-- B-tree (Balanced Tree/сбалансированное дерево) - создается по умолчанию, когда мы создаем некоторую колонку с PRIMARY KEY или UNIQUE или просто выполняем команду создания индекса без доп опций:
CREATE INDEX index_name ON table_name(column_name);

-- Сложность поиска (как и в принципе по сбалансированным деревьям) O(logN) - увеличение данных влияет на результат поиска, но не очень сильно

-- В большинстве случаев достаточно индекса B-tree и соответственно он будет лучим выбором

-- Поддерживает операторы примененные к проиндексированной колонке:
-- <, >, <=, >=, =
-- BETWEEN, IN
-- LIKE 'abc%' (но не '%abc')
-- IS NULL и IS NOT NULL  (Индексирует и значение NULL)



--                                                  Hash

-- Hash (Хэш-индекс) если мы хотим создать хэш-индекс, то нужно дописать спец синтаксис:
CREATE INDEX index_name ON table_name USING HASH (column_name);

-- Сложность поиска по колонке с этим индексом O(1) - тоесть мгновенно и не зависит от колличества данных

-- Поддерживает только оператор '=' для поиска по проиндексированной колонке. Тоесть по быстродействию может обойти B-tree, если предполагается, что при запросах в большинстве случаев будет использоваться именно '='. Но на практике он побеждает B-tree не очень сильно, потому используется не часто.

-- Не отражается в журнале предзаписи WAL (в него записываются все изменения в фаилах до того как они сделаны, позволяет восстановить БД если произошел какойто сбой, уменьшает число записей запросов на диск, тк для подтверждения транзации нужны только записи журнала, а не записи каждого изменения в фаилах в результате транзакции). Значит в результате сбоя придется делать реиндекс, а реиндекс на большом числе данных, к которым идет большое число запросов это очень не простая задача



--                                          Специализированные индесы

-- Специализированные индесы - используются очень редко и желательно их применять специалистам с познаниями в мат анализе, статистике, структурах даннгых итд


-- 1. GiST (обобщенное дерево поиска) - применяется для индексации геометрических и текстовых типов данных, например для организации полнотекстового поиска.
-- Занимает меньше места на диске чем GIN, но может быть менее эффективен изза дополнительных проверок
-- Может не сработать на огромном числе строк

-- 2. GIN (обобщенный обратный) - применяется обычно для индесации по колонке с типом массива, набора(рэндж), жсон, пар ключ-значение. Так же можно использовать для организации полнотекстового поиска(тут имются ввиду и лайк и регулярки ??), с более хитрыми запросами чем просто 'abc%'
-- Может не сработать на огромном числе строк

-- GiST и GIN - Основаны на модуле pg_trgm, который предоставляет функции и операторы для определения схожести алфавитно-цифровых строк, на основе так называемых триграмм/триграфов(группа 3х последовательных символов взятых из строки) и мы можем измерить схожеть 2х строк подсчитав число триграмм, которые есть в обеих

-- 3. SP-GiST (GiST с двоичным разбиением пространства) - используется для наборов данных, которые подразумевают естественную упорядоченность, но не являются сбалансированными, например телефонные номера, которые упорядочены по коду страны, оператору, но остальная часть номера довыольно рандомна.

-- 4. BRIN (блочно диапазонный) - полезен на огромных наборах данных, которые подразумевают естественную упорядоченность, например почтовые индексы или временные метки



--                                 EXPLAIN, EXPLAIN ANALYZE, планировщик запросов

-- Перед тем как построить новый индекс нужно понять какой именно это будет индекс, или какие есть проблемы с уже существующими индексами, чтобы перестроить их или запросы. Если у нас есть проблема с производительностью, в принципе нужно понять в чем она

EXPLAIN query; -- команда, аналитический инструмент, выдает вместо результата план исполнения запроса, где будет написано каким образом он выполняется, виды сканирования по которым он производится. Так же выдаст инфу про то какие касты(догадка планировщика о том как долго будет исполняться некий стэйтмент/утверждение в запросе, по сумме затрат по работе с диском или процессором) предположительно возникают. Сам запрос реально выполняться не будет, так что не стоит волноваться о запросах выполняющихся долго.
-- query - например SELECT-запрос, тоесть просто ставим команду перед необходимым запросом и запускаем.

-- Оценка планировщика не всегда может достаточно точно отражать реальность, а гдето и совсем не точно

EXPLAIN ANALYZE query; -- команда и проводит анализ и прогоняет сам запрос и показывает результат и плана и реального примера для более точной и полной инфы



--                                        ANALYZE, планировщик запросов

ANALYZE [table_name [(column1, column2...)]] -- тоесть можно дополнительно задавть отдельные таблицы и их колонки
-- собирает статистику по данным таблицы, помещает результаты в pg_statistic таблицу
-- планировщик смотрит на статистику при построении плана

-- После запуска ANALYZE запросы могут работать быстрее (изза кэширования)

-- Стоит запускать как минимум раз в день, чем больше обновлений данных, тем чаще надо запускать
-- Autovacuum (если включен) в том числе запускает и ANALYZE




--                                Примеры построения индексов: 1 Подготовка таблицы

-- Создадим таблицу:
CREATE TABLE perf_test
(
  id INTEGER,
  reason TEXT COLLATE "C", -- COLLATE "C" - говорим не использовать таблице колэйшен, тоесть правила сортировки и сравнения, если они по умолчанию привязаны например к кирилице, а будет использоваться просто побайтовое сравнение символов в строке, тк будем использовать латиницу для этих строк
  annotation TEXT COLLATE "C"
);

-- Заполним таблицу случайными данными:
INSERT INTO perf_test(id, reason, annotation)
SELECT s.id, MD5(RANDOM()::TEXT), NULL
FROM GENERATE_SERIES(1, 10000000) AS s(id)
ORDER BY RANDOM();
-- Отдельно заполним колонку annotation, на всякий, чтоб не генерило одинаковый текст
UPDATE perf_test
SET annotation = UPPER(MD5(RANDOM()::TEXT))

-- Получим таблицу из 10 миллионов строк хэшей MD5 обычных и в верхнем регистре



--                     Примеры построения индексов: 2 Поиск и индекс по id, EXPLAIN, ANALYZE

-- Данный запрос будет испольняться примерно 2 секунды, что достаточно долго:
SELECT * FROM perf_test WHERE id = 3700000;

-- Проверим при помощи EXPLAIN(или EXPLAIN ANALYZE) почему он исполнялся так долго:
EXPLAIN SELECT * FROM perf_test WHERE id = 3700000;  --> среди прочей инфы видим 'Paralel Seq Scan', тоесть чтение выполняется при помощи самого долгого последовательного сканирования

-- Создадим B-tree индекс для поиска по id в этой таблице. Построение индекса таж же занимает время если строк много, тут примерно 11 секунд:
CREATE INDEX idx_perf_test_id ON perf_test(id);
-- idx_perf_test_id - имя для индекса

-- Проверим еще раз при помощи EXPLAIN:
EXPLAIN SELECT * FROM perf_test WHERE id = 3700000;  --> среди прочей инфы видим 'Bitmap Index Scan', тоесть теперь производится побитовое индексное сканирование

-- Теперь тот же запрос будет испольняться примерно 60 милисекун, илиза 0.06 секунды:
SELECT * FROM perf_test WHERE id = 3700000;



--           Примеры построения индексов: 3 Поиск по шаблону LIKE и создание индекса, индекс по выражению

-- Сделаем селект по шаблону LIKE сразу по 2м колонкам, он отрабатывает примерно за 2.5 секунды
SELECT * FROM perf_test WHERE reason LIKE 'bc%' AND annotation LIKE 'AB%';

-- Проверим почему так медленно:
EXPLAIN SELECT * FROM perf_test WHERE reason LIKE 'bc%' AND annotation LIKE 'AB%'; --> среди прочей инфы видим 'Paralel Seq Scan'

-- Чтобы ускорить такие типы запросов, построим индекс сразу по 2м колонкам (построение заняло почти 30 секунд)
CREATE INDEX idx_perf_test_reason_annotation ON perf_test(reason, annotation);

-- Проверим еще раз:
EXPLAIN SELECT * FROM perf_test WHERE reason LIKE 'bc%' AND annotation LIKE 'AB%'; --> среди прочей инфы видим 'Index Scan'

-- Теперь тот же запрос занимает 200 милисекунд
SELECT * FROM perf_test WHERE reason LIKE 'bc%' AND annotation LIKE 'AB%';


-- Построение индекса по 2м колонкам дает так же нам возможность индексного поиска по первой из них отдельно, но не дает отдельного поиска по второй, потому если мы хотим такой, то придется сделать отдельный индекс
EXPLAIN SELECT * FROM perf_test WHERE reason LIKE 'bc%'; --> 'Bitmap Index Scan'  и 300 милисекунд на запрос
EXPLAIN SELECT * FROM perf_test WHERE annotation LIKE 'AB%'; --> 'Paralel Seq Scan'  и 1.2 секунды на запрос

-- Попробуем решить проблему простым построением индекса:
CREATE INDEX idx_perf_test_annotation ON perf_test(annotation);
-- Проверим:
EXPLAIN SELECT * FROM perf_test WHERE annotation LIKE 'AB%'; --> 'Bitmap Index Scan'  и 370 милисекунд на запрос


-- Но если поиск будет идти с использованием функций преобразования строк, то не будет поиска по индексу созданному для колонки
SELECT * FROM perf_test WHERE LOWER(annotation) LIKE 'ab%' --> почти 2 секунды
EXPLAIN SELECT * FROM perf_test WHERE LOWER(annotation) LIKE 'ab%' --> 'Paralel Seq Scan'

-- Чтобы заработало нужно создать отдельный индекс конкретно для использования с этой функции (индекс по выражению)
CREATE INDEX idx_perf_test_annotation_lower ON perf_test(LOWER(annotation));
-- Проверим
SELECT * FROM perf_test WHERE LOWER(annotation) LIKE 'ab%' --> почти 300 милисекунд
EXPLAIN SELECT * FROM perf_test WHERE LOWER(annotation) LIKE 'ab%' --> 'Bitmap Index Scan'



--                              Примеры построения индексов: 4 Создание индекса GIN

-- Если мы хотим усложнить регулярное выражение используемое в LIKE и осуществлять индексный поиск по нему, то придется использовать специализированный индекс

-- По простому выражению работает ранее созданный индекс:
SELECT * FROM perf_test WHERE reason LIKE 'bc%'; --> 300 милисекунд
-- Но вот по более сложному
SELECT * FROM perf_test WHERE reason LIKE '%bc%'; --> 3.3 секунды, тоесть параллельное последовательное сканирование
EXPLAIN SELECT * FROM perf_test WHERE reason LIKE '%bc%'; --> 'Paralel Seq Scan'

-- Чтобы ускорить текстматчинг, тоесть поиск по шаблонам/рег выражением нужно построить индекс GIN или GiST

-- Для этого сперва нужно запустить/подключить расширение модуля pg_trgm
CREATE EXTENSION pg_trgm;

-- Далее можем создать и сам индекс. Заняло 2 минуты
CREATE INDEX trgm_idx_perf_test_reason ON perf_test USING GIN (reason gin_trgm_ops);

-- Проверим
EXPLAIN ANALYZE SELECT * FROM perf_test WHERE reason LIKE '%bc%'; --> 'Seq Scan' тоесть все равно последовательное сканирование и 2.7 секунд на запрос, все потому что нет гарантий, что будет использоваться индексный поиск, в данном случае он не был использован тк запрос выводит более миллиона строк

-- Но если сократим число строк в выводе задав более редкую подстроку для выборки, тогда появляется причина переходить на индексный поиск
EXPLAIN ANALYZE SELECT * FROM perf_test WHERE reason LIKE '%fаbc%'; --> 'Bitmap Index Scan' и 500 милисекунд на запрос















--
